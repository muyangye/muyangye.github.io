---
title: 'On Camera'
date: 2024-06-06
permalink: /posts/2024/06/blog-post-1/
tags:
  - camera
  - linear algebra
  - game engine
  - novel view synthesis
---

Have you wondered how cameras turn an object in 3D space to a 2D image? This post covers the entire process and goes very
deep into half of that process. I am writing this post because this is such a simple subject and yet there has not been
any post that clearly explains it (mainly due to too-many terminologies with the same meaning, and most posts just analyze math without even
telling the basic concepts). I personally struggled a lot on this during my research experience, so I hope this post will
help whoever sees it in the future.

## Space
Before diving into cameras, we need to first understand space. Space is probably the most basic and important concept to understand, unfortunately as far as I know, no tutorial on cameras
ever covered space. I don't have a precise definition of space but you can essentially understand space in this way:
**In object X's space, X itself is at (0, 0, 0). No matter X's rotation, The lines that cross X's centroid orthogonally
from "left-right", "high-low", "forward-backward" are x-axis, y-axis, z-axis, respectively**. This definition means that
coordinate axes **in different objects' spaces might be different**. The meaning/significance/essence of an object's space
is that it captures the **relative transform of other objects**. To better illustrate this, consider the following picture:

<p align="center">
  <img src="/images/blog_post_1/space.png" alt="Space"/>
</p>

In this picture, the coordinates of Cube O, Cube A, and Cube B are *(0, 0, 0)*, *(3, 2, 0)*, and *(-4, 0, 5)* in **world space**
(or, Cube O's space since it's at origin). They mean that starting from origin or Cube O, we should go +3 units in x-axis,
+2 units in y-axis to reach Cube A, and we should go -4 units in x-axis, +5 units in z-axis to reach Cube B. Now, if we take
everything in Cube A's space, **Cube A itself is at *(0, 0, 0)***, and Cube O is located at *(-3, -2, 0)* because we need to
go -3 units in x-axis, -2 units in y-axis to reach Cube O. Similarly, the coordinate of Cube B in Cube A's space is
*(-7, -2, 5)*.

Extremely simple concept isn't it? just to reiterate, an object's space captures the **relative transform of other objects**.

## "Space Transformation Matrix"
In the above content, we learned what is space and saw an example of turning the coordinate in one space to the coordinate
in another space. However, the reason why we can easily derive the coordinate/space transformation is because all cubes are
not rotated. If we take into account of rotation and scale, we need a more systematic way of doing space transition:
**"space transformation matrix"** (quoted because I invented this term). Let's call this matrix **M**, **M** takes an
input of one object space's coordinates and outputs the same position in another object space's coordinates like this:

<p align="center">
  <img src="/images/blog_post_1/space_transformation_matrix.png" alt="Space Transformation Matrix"/>
</p>

Specifically, the first 3x3 entries applies the transformation of scale and rotation, and the last column applies the
translational (translation is the terminology for position) transformation. For more detailed breakdown and how to extract standalone scale, rotation, translation matrices,
please give [this post](https://www.brainvoyager.com/bv/doc/UsersGuide/CoordsAndTransforms/SpatialTransformationMatrices.html)
a look which is very well written.

<p align="center">
  <img src="/images/blog_post_1/space_transformation_matrix_entries.png" alt="Space Transformation Matrix Entries"/>
</p>

How do we calculate **M**? The answer is dependent on the two spaces we are transforming from and to. We just need to
define the required scale (**S**), rotational(**R**), and translational(**T**) changes/matrices of from -> to and then
**M = S * R * T** (or **T * R * S** depending on the context). However, here
is a very common **M** we should know and I will use it to demonstrate the magic of transformation matrix, which is the
transformation matrix from an arbitrary object's space to world space. **Given the object's scale s, rotation r (a quaternion),
and translation t in *world space*, M is:**

<p align="center">
  <img src="/images/blog_post_1/object_to_world.png" alt="Object To World"/>
</p>

This looks intimidating, but since I am only demonstrating the cubes and they are not rotated or scaled, the entire upper-left 3x3
sub-matrix is just an identity matrix. For example, let's say I want to calculate Cube B's coordinate in world space, **given Cube
B's coordinate in Cube A's space and the transformation matrix M** (plugging in Cube A's scale *<1, 1, 1>*, rotation *<0, 0, 0, 0>*,
and translation *<3, 2, 0>* in world space to the big formula above) **from Cube A's space to world space**, the result is:

<p align="center">
  <img src="/images/blog_post_1/result.png" alt="Result"/>
</p>

Where *(-4, 0, 5)* is indeed Cube B's coordinate in world space! We have now seen how "space transformation matrix" can
help us transform the coordinates in one space to another space. If rotation and scale are added, this method still works.
The resulting coordinate is likely going to contain decimals which are hard to plot initially in the **Space** section.

## Finally Back to Cameras...
Sorry for the long detour! But we finally possess the necessary prerequisites for understanding camera (and you will realize
how stupid it is to have so many terminologies like view matrix/camera extrinsic/camera intrinsic/whatever instead of just
**the space transformation matrix from X's space to Y's space**).

So, what a camera essentially does is that it **transforms a 3D object to a 2D image, meaning transforms a bunch of 3D coordinates
to 2D coordinates**. It receives an object's coordinates in **world space** initially and transforms them in 2 phases:

<p align="center">
  <img src="/images/blog_post_1/camera.jpg" alt="Camera"/>
</p>

- Phase 1: Transform coordinates in world space to coordinates in camera space. Like every space transformation, this is
done by a space transformation matrix **M** called view matrix or camera extrinsic, or, I just call it the space transformation
matrix from world space to camera space. If you think about it, you already know how to calculate **M** based on previous
reading:
  - Camera is no different than a cube or an object, so you can easily get the space transformation matrix **M'** from camera
  space to world space given camera's scale, rotation, and translation in world space. Just plug in those to the giant formula
  above.
  - **M'** transforms coordinates from camera space to world space, **M** transforms coordinates from world space to camera space. Let's
  say we initially have a translation vector **X** in camera space, this means **M * M' * X = X** (basically it means that
  after transforming **X** from camera space to world space, we should be able to get the same **X** in camera space after
  transforming from world space back to camera space), which means **M * M' = I** ==> **M** and **M'** are inverse of each other
  ==> **M = inv(M')**.
- Phase 2: Transform coordinates in camera space to coordinates in image space. This space transformation matrix is called
camera intrinsic. I am not an expert on this matrix, but it has a **focal length** and works like the pinhole camera in
middle school Physics. For more information, [this page](https://ksimek.github.io/2013/08/13/intrinsic/) is a great introduction!

And that's it! That's entirely how a camera works! I am so disappointed that I have seen no clear and thorough tutorial on
such a simple subject :( By the way, please note that there are other types of cameras than pinhole cameras, and they may
have a different Phase 2 (very rarely, even a different Phase 1).

## Novel View Synthesis and Unity's cameraToWorldMatrix and worldToCameraMatrix, Lessons Learned
